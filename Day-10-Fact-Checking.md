# Day 10: Fact-Checking & Hallucination Defense
**Project:** Ensuring Data Integrity for KreyolAIHub

### The Strategy
I learned that AI can "hallucinate" (invent facts). To prevent this, I now use **Verification Prompts** that force the AI to cite sources, provide URLs, and double-check its own logic before I share information with the community.

### Why this is a Specialist Skill
Standard users spread AI misinformation. A Specialist builds "Guardrails" into their prompts to ensure that advice given to schools or parents is safe and factually grounded.

### Key Technique: The "Confidence Check"
I now ask the AI to "Rate your confidence in this specific fact from 1-10." If it is below 9, I perform manual research to verify.
